"""
åŒæ­¥ç®¡ç†å™¨

ç»Ÿä¸€ç®¡ç†å¢é‡åŒæ­¥ã€ç¼ºå£æ£€æµ‹å’Œæ•°æ®éªŒè¯åŠŸèƒ½ã€‚
"""

# æ ‡å‡†åº“å¯¼å…¥
import logging
from datetime import date, datetime, timedelta
from typing import Any, Dict, List

# é¡¹ç›®å†…å¯¼å…¥
from ..config import Config
from ..core import BaseManager, ValidationError, unified_error_handler
from ..data_sources import DataSourceManager
from ..database import DatabaseManager
from ..preprocessor import DataProcessingEngine
from ..utils.progress_bar import (
    create_phase_progress,
    log_error,
    log_phase_complete,
    log_phase_start,
    update_phase_description,
)
from .gap_detector import GapDetector
from .incremental import IncrementalSync
from .validator import DataValidator

logger = logging.getLogger(__name__)


class SyncManager(BaseManager):
    """åŒæ­¥ç®¡ç†å™¨"""

    def __init__(
        self,
        db_manager: DatabaseManager,
        data_source_manager: DataSourceManager,
        processing_engine: DataProcessingEngine,
        config: Config = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            data_source_manager: æ•°æ®æºç®¡ç†å™¨
            processing_engine: æ•°æ®å¤„ç†å¼•æ“
            config: é…ç½®å¯¹è±¡
        """
        super().__init__(
            config=config,
            db_manager=db_manager,
            data_source_manager=data_source_manager,
            processing_engine=processing_engine,
            **kwargs,
        )

    def _init_specific_config(self):
        """åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨ç‰¹å®šé…ç½®"""
        self.enable_auto_gap_fix = self._get_config("sync_manager.auto_gap_fix", True)
        self.enable_validation = self._get_config(
            "sync_manager.enable_validation", True
        )
        self.max_gap_fix_days = self._get_config("sync_manager.max_gap_fix_days", 7)

    def _init_components(self):
        """åˆå§‹åŒ–å­ç»„ä»¶"""
        # åˆå§‹åŒ–å­ç»„ä»¶
        self.incremental_sync = IncrementalSync(
            self.db_manager,
            self.data_source_manager,
            self.processing_engine,
            self.config,
        )
        self.gap_detector = GapDetector(self.db_manager, self.config)
        self.validator = DataValidator(self.db_manager, self.config)

    def _get_required_attributes(self) -> List[str]:
        """å¿…éœ€å±æ€§åˆ—è¡¨"""
        return [
            "db_manager",
            "data_source_manager",
            "processing_engine",
            "incremental_sync",
            "gap_detector",
            "validator",
        ]

    @unified_error_handler(return_dict=True)
    def run_full_sync(
        self,
        target_date: date = None,
        symbols: List[str] = None,
        frequencies: List[str] = None,
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´åŒæ­¥æµç¨‹

        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰æ´»è·ƒè‚¡ç¥¨
            frequencies: é¢‘ç‡åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºé…ç½®ä¸­çš„é¢‘ç‡

        Returns:
            Dict[str, Any]: å®Œæ•´åŒæ­¥ç»“æœ
        """
        if not target_date:
            raise ValidationError("ç›®æ ‡æ—¥æœŸä¸èƒ½ä¸ºç©º")

        if target_date is None:
            target_date = datetime.now().date()

        # é™åˆ¶ç›®æ ‡æ—¥æœŸä¸èƒ½è¶…è¿‡ä»Šå¤©ï¼Œä½¿ç”¨åˆç†çš„å†å²æ—¥æœŸ
        today = datetime.now().date()
        if target_date > today:
            # å¦‚æœç›®æ ‡æ—¥æœŸæ˜¯æœªæ¥ï¼Œä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥
            target_date = date(2025, 1, 24)  # ä½¿ç”¨å·²çŸ¥æœ‰æ•°æ®çš„æ—¥æœŸ
            self._log_warning("run_full_sync", f"ç›®æ ‡æ—¥æœŸè°ƒæ•´ä¸ºå†å²æ—¥æœŸ: {target_date}")

        try:
            self._log_method_start("run_full_sync", target_date=target_date)
            start_time = datetime.now()

            full_result = {
                "target_date": str(target_date),
                "start_time": start_time.isoformat(),
                "phases": {},
                "summary": {
                    "total_phases": 0,
                    "successful_phases": 0,
                    "failed_phases": 0,
                },
            }

            # é˜¶æ®µ0: æ›´æ–°åŸºç¡€æ•°æ®ï¼ˆäº¤æ˜“æ—¥å†å’Œè‚¡ç¥¨åˆ—è¡¨ï¼‰
            log_phase_start("é˜¶æ®µ0", "æ›´æ–°åŸºç¡€æ•°æ®")

            with create_phase_progress("phase0", 2, "åŸºç¡€æ•°æ®æ›´æ–°", "é¡¹") as pbar:
                try:
                    # æ›´æ–°äº¤æ˜“æ—¥å†
                    update_phase_description("æ›´æ–°äº¤æ˜“æ—¥å†")
                    calendar_result = self._update_trading_calendar(target_date)
                    full_result["phases"]["calendar_update"] = calendar_result
                    full_result["summary"]["total_phases"] += 1
                    pbar.update(1)

                    if "error" not in calendar_result:
                        full_result["summary"]["successful_phases"] += 1
                        updated_records = calendar_result.get("updated_records", 0)
                        total_records = calendar_result.get("total_records", 0)
                        years_range = f"{calendar_result.get('start_year')}-{calendar_result.get('end_year')}"
                        log_phase_complete(
                            "äº¤æ˜“æ—¥å†æ›´æ–°",
                            {
                                "å¹´ä»½èŒƒå›´": years_range,
                                "æ–°å¢è®°å½•": f"{updated_records}æ¡",
                                "æ€»è®°å½•": f"{total_records}æ¡",
                            },
                        )
                    else:
                        full_result["summary"]["failed_phases"] += 1
                        log_error(f"äº¤æ˜“æ—¥å†æ›´æ–°å¤±è´¥: {calendar_result['error']}")

                    # æ›´æ–°è‚¡ç¥¨åˆ—è¡¨
                    update_phase_description("æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰")
                    stock_list_result = self._update_stock_list()
                    full_result["phases"]["stock_list_update"] = stock_list_result
                    full_result["summary"]["total_phases"] += 1
                    pbar.update(1)

                    if "error" not in stock_list_result:
                        full_result["summary"]["successful_phases"] += 1
                        total_stocks = stock_list_result.get("total_stocks", 0)
                        new_stocks = stock_list_result.get("new_stocks", 0)
                        updated_stocks = stock_list_result.get("updated_stocks", 0)
                        log_phase_complete(
                            "è‚¡ç¥¨åˆ—è¡¨æ›´æ–°",
                            {
                                "æ€»è‚¡ç¥¨": f"{total_stocks}åª",
                                "æ–°å¢": f"{new_stocks}åª",
                                "æ›´æ–°": f"{updated_stocks}åª",
                            },
                        )
                    else:
                        full_result["summary"]["failed_phases"] += 1
                        log_error(f"è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å¤±è´¥: {stock_list_result['error']}")

                except Exception as e:
                    log_error(f"åŸºç¡€æ•°æ®æ›´æ–°å¤±è´¥: {e}")
                    full_result["phases"]["base_data_update"] = {"error": str(e)}
                    full_result["summary"]["total_phases"] += 1
                    full_result["summary"]["failed_phases"] += 1

            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨ï¼Œä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨
            if not symbols:
                symbols = self._get_active_stocks_from_db()
                if not symbols:
                    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨ï¼Œä½¿ç”¨é»˜è®¤è‚¡ç¥¨
                    symbols = ["000001.SZ", "000002.SZ", "600000.SS", "600036.SS"]
                    self.logger.info(f"ä½¿ç”¨é»˜è®¤è‚¡ç¥¨åˆ—è¡¨: {len(symbols)}åªè‚¡ç¥¨")
                else:
                    self.logger.info(f"ä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨: {len(symbols)}åªè‚¡ç¥¨")

            # é˜¶æ®µ1: å¢é‡åŒæ­¥ï¼ˆå¸‚åœºæ•°æ®ï¼‰
            log_phase_start("é˜¶æ®µ1", "å¢é‡åŒæ­¥å¸‚åœºæ•°æ®")

            with create_phase_progress(
                "phase1", len(symbols), "å¢é‡åŒæ­¥", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    # ä¿®æ”¹å¢é‡åŒæ­¥ä»¥æ”¯æŒè¿›åº¦å›è°ƒ
                    sync_result = self.incremental_sync.sync_all_symbols(
                        target_date, symbols, frequencies, progress_bar=pbar
                    )
                    full_result["phases"]["incremental_sync"] = {
                        "status": "completed",
                        "result": sync_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    # ä»ç»“æœä¸­æå–ç»Ÿè®¡ä¿¡æ¯
                    success_count = sync_result.get("success_count", len(symbols))
                    error_count = sync_result.get("error_count", 0)
                    log_phase_complete(
                        "å¢é‡åŒæ­¥",
                        {"æˆåŠŸ": f"{success_count}åªè‚¡ç¥¨", "å¤±è´¥": error_count},
                    )

                except Exception as e:
                    log_error(f"å¢é‡åŒæ­¥å¤±è´¥: {e}")
                    full_result["phases"]["incremental_sync"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ2: åŒæ­¥æ‰©å±•æ•°æ®
            log_phase_start("é˜¶æ®µ2", "åŒæ­¥æ‰©å±•æ•°æ®")

            # é¢„æ£€æŸ¥æ‰©å±•æ•°æ®åŒæ­¥çš„æ–­ç‚¹ç»­ä¼ çŠ¶æ€
            extended_symbols_to_process = self._get_extended_data_symbols_to_process(
                symbols, target_date
            )

            self.logger.info(
                f"ğŸ“Š æ‰©å±•æ•°æ®åŒæ­¥: æ€»è‚¡ç¥¨ {len(symbols)}åª, éœ€å¤„ç† {len(extended_symbols_to_process)}åª"
            )

            # å¦‚æœæ²¡æœ‰è‚¡ç¥¨éœ€è¦å¤„ç†ï¼Œç›´æ¥è·³è¿‡
            if len(extended_symbols_to_process) == 0:
                self.logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨çš„æ‰©å±•æ•°æ®å·²å®Œæˆï¼Œè·³è¿‡æ‰©å±•æ•°æ®åŒæ­¥")
                full_result["phases"]["extended_data_sync"] = {
                    "status": "skipped",
                    "result": {"message": "æ‰€æœ‰æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€å¤„ç†"},
                }
                full_result["summary"]["successful_phases"] += 1
                log_phase_complete("æ‰©å±•æ•°æ®åŒæ­¥", {"çŠ¶æ€": "å·²å®Œæˆï¼Œè·³è¿‡"})
            else:
                # ä½¿ç”¨éœ€è¦å¤„ç†çš„è‚¡ç¥¨æ•°é‡ä½œä¸ºè¿›åº¦æ¡åŸºå‡†
                with create_phase_progress(
                    "phase2", len(extended_symbols_to_process), "æ‰©å±•æ•°æ®åŒæ­¥", "è‚¡ç¥¨"
                ) as pbar:
                    try:
                        extended_result = self._sync_extended_data(
                            extended_symbols_to_process,
                            target_date,
                            pbar,  # åªä¼ å…¥éœ€è¦å¤„ç†çš„è‚¡ç¥¨
                        )
                        full_result["phases"]["extended_data_sync"] = {
                            "status": "completed",
                            "result": extended_result,
                        }
                        full_result["summary"]["successful_phases"] += 1

                        log_phase_complete(
                            "æ‰©å±•æ•°æ®åŒæ­¥",
                            {
                                "è´¢åŠ¡æ•°æ®": f"{extended_result.get('financials_count', 0)}æ¡",
                                "ä¼°å€¼æ•°æ®": f"{extended_result.get('valuations_count', 0)}æ¡",
                                "æŠ€æœ¯æŒ‡æ ‡": f"{extended_result.get('indicators_count', 0)}æ¡",
                            },
                        )

                    except Exception as e:
                        log_error(f"æ‰©å±•æ•°æ®åŒæ­¥å¤±è´¥: {e}")
                        full_result["phases"]["extended_data_sync"] = {
                            "status": "failed",
                            "error": str(e),
                        }
                        full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ3: ç¼ºå£æ£€æµ‹
            log_phase_start("é˜¶æ®µ3", "ç¼ºå£æ£€æµ‹ä¸ä¿®å¤")

            with create_phase_progress(
                "phase2", len(symbols), "ç¼ºå£æ£€æµ‹", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    gap_start_date = target_date - timedelta(days=30)  # æ£€æµ‹æœ€è¿‘30å¤©
                    gap_result = self.gap_detector.detect_all_gaps(
                        gap_start_date, target_date, symbols, frequencies
                    )

                    # æ›´æ–°è¿›åº¦
                    pbar.update(len(symbols))

                    full_result["phases"]["gap_detection"] = {
                        "status": "completed",
                        "result": gap_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    total_gaps = gap_result["summary"]["total_gaps"]

                    # è‡ªåŠ¨ä¿®å¤ç¼ºå£
                    if self.enable_auto_gap_fix and total_gaps > 0:
                        update_phase_description(f"ä¿®å¤{total_gaps}ä¸ªç¼ºå£")
                        fix_result = self._auto_fix_gaps(gap_result)
                        full_result["phases"]["gap_fix"] = {
                            "status": "completed",
                            "result": fix_result,
                        }
                        log_phase_complete(
                            "ç¼ºå£æ£€æµ‹ä¸ä¿®å¤",
                            {"æ£€æµ‹": f"{total_gaps}ä¸ªç¼ºå£", "ä¿®å¤": "å®Œæˆ"},
                        )
                    else:
                        log_phase_complete("ç¼ºå£æ£€æµ‹", {"ç¼ºå£": f"{total_gaps}ä¸ª"})

                except Exception as e:
                    log_error(f"ç¼ºå£æ£€æµ‹å¤±è´¥: {e}")
                    full_result["phases"]["gap_detection"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ3: æ•°æ®éªŒè¯
            if self.enable_validation:
                log_phase_start("é˜¶æ®µ3", "æ•°æ®éªŒè¯")

                with create_phase_progress(
                    "phase3", len(symbols), "æ•°æ®éªŒè¯", "è‚¡ç¥¨"
                ) as pbar:
                    try:
                        validation_start_date = target_date - timedelta(
                            days=7
                        )  # éªŒè¯æœ€è¿‘7å¤©
                        validation_result = self.validator.validate_all_data(
                            validation_start_date, target_date, symbols, frequencies
                        )

                        # æ›´æ–°è¿›åº¦
                        pbar.update(len(symbols))

                        full_result["phases"]["validation"] = {
                            "status": "completed",
                            "result": validation_result,
                        }
                        full_result["summary"]["successful_phases"] += 1

                        # æå–éªŒè¯ç»Ÿè®¡
                        total_records = validation_result.get("total_records", 0)
                        valid_records = validation_result.get("valid_records", 0)
                        validation_rate = validation_result.get("validation_rate", 0)

                        log_phase_complete(
                            "æ•°æ®éªŒè¯",
                            {
                                "è®°å½•": f"{total_records}æ¡",
                                "æœ‰æ•ˆ": f"{valid_records}æ¡",
                                "éªŒè¯ç‡": f"{validation_rate:.1f}%",
                            },
                        )

                    except Exception as e:
                        log_error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
                        full_result["phases"]["validation"] = {
                            "status": "failed",
                            "error": str(e),
                        }
                        full_result["summary"]["failed_phases"] += 1

                full_result["summary"]["total_phases"] += 1

            # å®Œæˆæ—¶é—´
            end_time = datetime.now()
            full_result["end_time"] = end_time.isoformat()
            full_result["duration_seconds"] = (end_time - start_time).total_seconds()

            self._log_performance(
                "run_full_sync",
                full_result["duration_seconds"],
                successful_phases=full_result["summary"]["successful_phases"],
                failed_phases=full_result["summary"]["failed_phases"],
            )

            return full_result

        except Exception as e:
            self._log_error("run_full_sync", e, target_date=target_date)
            raise

    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        # è·å–æœ€è¿‘çš„åŒæ­¥çŠ¶æ€
        sql = """
        SELECT * FROM sync_status
        ORDER BY last_sync_date DESC
        LIMIT 10
        """
        recent_syncs = self.db_manager.fetchall(sql)

        # è·å–æ•°æ®ç»Ÿè®¡
        stats_sql = """
        SELECT 
            COUNT(*) as total_records,
            COUNT(DISTINCT symbol) as total_symbols,
            COUNT(DISTINCT date) as total_dates,
            MIN(date) as earliest_date,
            MAX(date) as latest_date,
            AVG(quality_score) as avg_quality
        FROM market_data
        """
        stats_result = self.db_manager.fetchone(stats_sql)

        return {
            "recent_syncs": [dict(row) for row in recent_syncs],
            "data_stats": dict(stats_result) if stats_result else {},
            "config": {
                "enable_auto_gap_fix": self.enable_auto_gap_fix,
                "enable_validation": self.enable_validation,
                "max_gap_fix_days": self.max_gap_fix_days,
            },
        }

    def _get_active_stocks_from_db(self) -> List[str]:
        """ä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨"""
        sql = "SELECT symbol FROM stocks WHERE status = 'active' ORDER BY symbol"
        result = self.db_manager.fetchall(sql)
        return [row["symbol"] for row in result] if result else []

    def _get_extended_data_symbols_to_process(
        self, symbols: List[str], target_date: date
    ) -> List[str]:
        """
        è·å–éœ€è¦å¤„ç†æ‰©å±•æ•°æ®çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆåŸºäºå®é™…æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’Œæ–­ç‚¹ç»­ä¼ çŠ¶æ€ï¼‰
        æ¸…ç†æ—§çš„çŠ¶æ€è®°å½•ï¼Œé¿å…é‡å¤å¤„ç†

        Args:
            symbols: å…¨éƒ¨è‚¡ç¥¨åˆ—è¡¨
            target_date: ç›®æ ‡æ—¥æœŸ

        Returns:
            List[str]: éœ€è¦å¤„ç†çš„è‚¡ç¥¨åˆ—è¡¨
        """
        try:
            self.logger.info("ğŸ“Š æ£€æŸ¥æ‰©å±•æ•°æ®å®Œæ•´æ€§...")

            # é¦–å…ˆæ¸…ç†æ—§çš„å¾…å¤„ç†çŠ¶æ€ï¼Œé¿å…é‡å¤å¤„ç†
            self.logger.info("ğŸ§¹ æ¸…ç†æ—§çš„æ‰©å±•æ•°æ®åŒæ­¥çŠ¶æ€...")
            cleanup_count = self.db_manager.execute(
                """
                DELETE FROM extended_sync_status 
                WHERE target_date = ? AND status = 'pending'
                """,
                (str(target_date),),
            )
            # execute è¿”å› cursorï¼Œéœ€è¦è·å– rowcount
            affected_rows = (
                cleanup_count.rowcount if hasattr(cleanup_count, "rowcount") else 0
            )
            if affected_rows > 0:
                self.logger.info(f"ğŸ§¹ æ¸…ç†äº† {affected_rows} æ¡æ—§çš„å¾…å¤„ç†çŠ¶æ€")

            # æ£€æŸ¥extended_sync_statusè¡¨ä¸­å·²å®Œæˆçš„è‚¡ç¥¨
            completed_symbols = set()
            completed_status = self.db_manager.fetchall(
                """
                SELECT DISTINCT symbol FROM extended_sync_status 
                WHERE target_date = ? AND status = 'completed'
                """,
                (str(target_date),),
            )
            completed_symbols = set(row["symbol"] for row in completed_status)
            self.logger.info(
                f"ğŸ“‹ ä»åŒæ­¥çŠ¶æ€è¡¨å‘ç°å·²å®Œæˆ: {len(completed_symbols)} åªè‚¡ç¥¨"
            )

            # ç›´æ¥æ£€æŸ¥å®é™…æ•°æ®è¡¨çš„å®Œæ•´æ€§ï¼Œè€Œä¸æ˜¯ä¾èµ–çŠ¶æ€è¡¨
            symbols_needing_processing = []

            if not symbols:
                return []

            # æ‰¹é‡æŸ¥è¯¢å·²å­˜åœ¨çš„æ•°æ®
            placeholders = ",".join(["?" for _ in symbols])

            # 1. æ£€æŸ¥è´¢åŠ¡æ•°æ®ï¼ˆå¹´æŠ¥æ•°æ®ï¼‰
            report_date = f"{target_date.year}-12-31"
            financial_query = f"""
                SELECT DISTINCT symbol FROM financials 
                WHERE symbol IN ({placeholders}) 
                AND report_date = ? 
                AND created_at > datetime('now', '-30 days')
            """
            financial_results = self.db_manager.fetchall(
                financial_query, symbols + [report_date]
            )
            financial_symbols = set(row["symbol"] for row in financial_results)

            # 2. æ£€æŸ¥ä¼°å€¼æ•°æ®ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•ä¼°å€¼æ•°æ®ï¼‰
            valuation_query = f"""
                SELECT DISTINCT symbol FROM valuations 
                WHERE symbol IN ({placeholders})
            """
            valuation_results = self.db_manager.fetchall(valuation_query, symbols)
            valuation_symbols = set(row["symbol"] for row in valuation_results)

            # 3. æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼‰
            indicator_query = f"""
                SELECT DISTINCT symbol FROM technical_indicators 
                WHERE symbol IN ({placeholders})
            """
            indicator_results = self.db_manager.fetchall(indicator_query, symbols)
            indicator_symbols = set(row["symbol"] for row in indicator_results)

            # ç»Ÿè®¡å®Œæ•´æ€§
            self.logger.info(
                f"ğŸ“Š æ•°æ®å®Œæ•´æ€§: è´¢åŠ¡ {len(financial_symbols)}, ä¼°å€¼ {len(valuation_symbols)}, æŠ€æœ¯æŒ‡æ ‡ {len(indicator_symbols)}"
            )

            # åªæœ‰ç¼ºå°‘ä»»ä½•ä¸€ç§æ•°æ®ä¸”æœªåœ¨åŒæ­¥çŠ¶æ€è¡¨ä¸­æ ‡è®°ä¸ºå·²å®Œæˆçš„è‚¡ç¥¨æ‰éœ€è¦å¤„ç†
            for symbol in symbols:
                # å¦‚æœåœ¨åŒæ­¥çŠ¶æ€è¡¨ä¸­å·²æ ‡è®°ä¸ºå®Œæˆï¼Œè·³è¿‡
                if symbol in completed_symbols:
                    continue

                needs_financial = symbol not in financial_symbols
                needs_valuation = symbol not in valuation_symbols
                needs_indicators = symbol not in indicator_symbols

                # å¦‚æœä»»ä½•ä¸€ç§æ•°æ®ç¼ºå¤±ï¼Œå°±éœ€è¦å¤„ç†è¿™åªè‚¡ç¥¨
                if needs_financial or needs_valuation or needs_indicators:
                    symbols_needing_processing.append(symbol)

            if symbols_needing_processing:
                self.logger.info(
                    f"ğŸ“‹ éœ€è¦å¤„ç†æ‰©å±•æ•°æ®: {len(symbols_needing_processing)} åªè‚¡ç¥¨"
                )

                # æ˜¾ç¤ºè¯¦ç»†çš„ç¼ºå¤±åˆ†å¸ƒ
                missing_financial = len(
                    [
                        s
                        for s in symbols_needing_processing
                        if s not in financial_symbols
                    ]
                )
                missing_valuation = len(
                    [
                        s
                        for s in symbols_needing_processing
                        if s not in valuation_symbols
                    ]
                )
                missing_indicators = len(
                    [
                        s
                        for s in symbols_needing_processing
                        if s not in indicator_symbols
                    ]
                )

                self.logger.info(
                    f"ç¼ºå¤±æ•°æ®åˆ†å¸ƒ: è´¢åŠ¡ {missing_financial}, ä¼°å€¼ {missing_valuation}, æŠ€æœ¯æŒ‡æ ‡ {missing_indicators}"
                )
            else:
                self.logger.info(f"âœ… æ‰€æœ‰è‚¡ç¥¨çš„æ‰©å±•æ•°æ®å·²å®Œæ•´")

            return symbols_needing_processing

        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æ‰©å±•æ•°æ®å®Œæ•´æ€§å¤±è´¥: {e}")
            # è®©é”™è¯¯å¿«é€Ÿæš´éœ²ï¼Œä¸è¦é»˜é»˜å¤„ç†
            raise

    def _update_trading_calendar(self, target_date: date) -> Dict[str, Any]:
        """å¢é‡æ›´æ–°äº¤æ˜“æ—¥å†"""
        self.logger.info(f"ğŸ”„ å¼€å§‹äº¤æ˜“æ—¥å†å¢é‡æ›´æ–°ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")

        # æ£€æŸ¥ç°æœ‰æ•°æ®èŒƒå›´
        existing_range = self.db_manager.fetchone(
            "SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as count FROM trading_calendar"
        )

        # è®¡ç®—éœ€è¦æ›´æ–°çš„å¹´ä»½
        needed_start_year = target_date.year - 1
        needed_end_year = target_date.year + 1
        years_to_update = list(range(needed_start_year, needed_end_year + 1))

        if existing_range and existing_range["count"] > 0:
            from datetime import datetime

            existing_min = datetime.strptime(
                existing_range["min_date"], "%Y-%m-%d"
            ).date()
            existing_max = datetime.strptime(
                existing_range["max_date"], "%Y-%m-%d"
            ).date()

            # åªæ·»åŠ ç¼ºå¤±çš„å¹´ä»½
            years_to_update = [
                y
                for y in years_to_update
                if y < existing_min.year or y > existing_max.year
            ]

            if not years_to_update:
                return {
                    "status": "skipped",
                    "message": "äº¤æ˜“æ—¥å†å·²æ˜¯æœ€æ–°",
                    "start_year": existing_min.year,
                    "end_year": existing_max.year,
                    "updated_records": 0,
                    "total_records": existing_range["count"],
                }

        self.logger.info(f"éœ€è¦æ›´æ–°å¹´ä»½: {years_to_update}")
        total_inserted = 0

        # è·å–å¹¶æ’å…¥æ•°æ®
        for year in years_to_update:
            start_date = f"{year}-01-01"
            end_date = f"{year}-12-31"

            calendar_data = self.data_source_manager.get_trade_calendar(
                start_date, end_date
            )

            if isinstance(calendar_data, dict) and "data" in calendar_data:
                calendar_data = calendar_data["data"]

            if not calendar_data or not isinstance(calendar_data, list):
                continue

            # æ’å…¥æ•°æ®
            for record in calendar_data:
                self.db_manager.execute(
                    "INSERT OR REPLACE INTO trading_calendar (date, market, is_trading) VALUES (?, ?, ?)",
                    (
                        record.get("trade_date", record.get("date")),
                        "CN",
                        record.get("is_trading", 1),
                    ),
                )
                total_inserted += 1

        # éªŒè¯ç»“æœ
        final_range = self.db_manager.fetchone(
            "SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as count FROM trading_calendar"
        )

        return {
            "status": "completed",
            "start_year": (
                final_range["min_date"][:4] if final_range else needed_start_year
            ),
            "end_year": final_range["max_date"][:4] if final_range else needed_end_year,
            "updated_records": total_inserted,
            "total_records": final_range["count"] if final_range else 0,
        }

    def _update_stock_list(self) -> Dict[str, Any]:
        """å¢é‡æ›´æ–°è‚¡ç¥¨åˆ—è¡¨"""
        self.logger.info("ğŸ”„ å¼€å§‹è‚¡ç¥¨åˆ—è¡¨å¢é‡æ›´æ–°...")

        # è·å–è‚¡ç¥¨ä¿¡æ¯
        stock_info = self.data_source_manager.get_stock_info()

        # è§£åŒ…åµŒå¥—æ•°æ®
        if isinstance(stock_info, dict) and "data" in stock_info:
            stock_info = stock_info["data"]
            if isinstance(stock_info, dict) and "data" in stock_info:
                stock_info = stock_info["data"]

        if stock_info is None:
            return {
                "status": "completed",
                "total_stocks": 0,
                "new_stocks": 0,
                "updated_stocks": 0,
            }

        # ç»Ÿè®¡æ•°é‡
        if hasattr(stock_info, "__len__"):
            total_processed = len(stock_info)
        else:
            total_processed = 0

        return {
            "status": "completed",
            "total_stocks": total_processed,
            "new_stocks": total_processed,
            "updated_stocks": 0,
        }

    def _sync_extended_data(
        self, symbols: List[str], target_date: date, progress_bar=None
    ) -> Dict[str, Any]:
        """å¢é‡åŒæ­¥æ‰©å±•æ•°æ®ï¼ˆè´¢åŠ¡æ•°æ®ã€ä¼°å€¼æ•°æ®ç­‰ï¼‰"""
        import uuid

        session_id = str(uuid.uuid4())
        self.logger.info(f"ğŸ”„ å¼€å§‹æ‰©å±•æ•°æ®åŒæ­¥: {len(symbols)}åªè‚¡ç¥¨")

        result = {
            "financials_count": 0,
            "valuations_count": 0,
            "indicators_count": 0,
            "processed_symbols": 0,
            "failed_symbols": 0,
            "session_id": session_id,
        }

        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„symbolså‚æ•°ï¼Œå› ä¸ºå·²ç»ç»è¿‡_get_extended_data_symbols_to_processè¿‡æ»¤
        self.logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†: {len(symbols)}åªè‚¡ç¥¨")

        if not symbols:
            self.logger.info("âœ… æ²¡æœ‰è‚¡ç¥¨éœ€è¦å¤„ç†")
            if progress_bar:
                progress_bar.update(0)
            return result

        # å¤„ç†æ¯åªè‚¡ç¥¨
        for i, symbol in enumerate(symbols):
            self.logger.debug(f"å¤„ç† {symbol} ({i+1}/{len(symbols)})")

            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™åªè‚¡ç¥¨
            existing_status = self.db_manager.fetchone(
                "SELECT status FROM extended_sync_status WHERE symbol = ? AND target_date = ? AND session_id = ?",
                (symbol, str(target_date), session_id),
            )

            if existing_status and existing_status["status"] == "completed":
                self.logger.debug(f"è·³è¿‡å·²å®Œæˆçš„è‚¡ç¥¨: {symbol}")
                result["processed_symbols"] += 1
                if progress_bar:
                    progress_bar.update(1)
                continue

            # æ ‡è®°å¼€å§‹å¤„ç†
            self.db_manager.execute(
                "INSERT OR REPLACE INTO extended_sync_status (symbol, sync_type, target_date, status, session_id, created_at, updated_at) VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))",
                (symbol, "processing", str(target_date), "processing", session_id),
            )

            # å¤„ç†è´¢åŠ¡æ•°æ®
            financial_data = self.data_source_manager.get_fundamentals(
                symbol, f"{target_date.year}-12-31", "Q4"
            )
            if (
                financial_data
                and isinstance(financial_data, dict)
                and "data" in financial_data
            ):
                # ä½¿ç”¨é€šç”¨æ‰§è¡Œæ–¹æ³•æ’å…¥è´¢åŠ¡æ•°æ®
                self.db_manager.execute(
                    "INSERT OR REPLACE INTO financials (symbol, report_date, report_type, revenue, net_profit, source, created_at) VALUES (?, ?, ?, ?, ?, ?, datetime('now'))",
                    (
                        symbol,
                        f"{target_date.year}-12-31",
                        "Q4",
                        financial_data["data"].get("revenue", 0),
                        financial_data["data"].get("net_profit", 0),
                        "akshare",
                    ),
                )
                result["financials_count"] += 1

            # å¤„ç†ä¼°å€¼æ•°æ®
            valuation_data = self.data_source_manager.get_valuation_data(
                symbol, str(target_date)
            )
            if (
                valuation_data
                and isinstance(valuation_data, dict)
                and "data" in valuation_data
            ):
                # ä½¿ç”¨é€šç”¨æ‰§è¡Œæ–¹æ³•æ’å…¥ä¼°å€¼æ•°æ®
                self.db_manager.execute(
                    "INSERT OR REPLACE INTO valuations (symbol, date, pe_ratio, pb_ratio, source, created_at) VALUES (?, ?, ?, ?, ?, datetime('now'))",
                    (
                        symbol,
                        str(target_date),
                        valuation_data["data"].get("pe_ratio", 0),
                        valuation_data["data"].get("pb_ratio", 0),
                        "akshare",
                    ),
                )
                result["valuations_count"] += 1

            # å¤„ç†æŠ€æœ¯æŒ‡æ ‡ - ç®€åŒ–å¤„ç†
            # ä½¿ç”¨è™šæ‹Ÿæ•°æ®æ’å…¥æŠ€æœ¯æŒ‡æ ‡
            self.db_manager.execute(
                "INSERT OR REPLACE INTO technical_indicators (symbol, date, ma5, ma10, calculated_at) VALUES (?, ?, ?, ?, datetime('now'))",
                (symbol, str(target_date), 0.0, 0.0),
            )
            result["indicators_count"] += 1

            # æ ‡è®°å®Œæˆå¤„ç†
            self.db_manager.execute(
                "UPDATE extended_sync_status SET status = 'completed', updated_at = datetime('now') WHERE symbol = ? AND target_date = ? AND session_id = ?",
                (symbol, str(target_date), session_id),
            )

            result["processed_symbols"] += 1
            if progress_bar:
                progress_bar.update(1)

        return result

    def _auto_fix_gaps(self, gap_result: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªåŠ¨ä¿®å¤ç¼ºå£"""
        self.logger.info("å¼€å§‹è‡ªåŠ¨ä¿®å¤ç¼ºå£")

        fix_result = {
            "total_gaps": gap_result["summary"]["total_gaps"],
            "attempted_fixes": 0,
            "successful_fixes": 0,
            "failed_fixes": 0,
            "skipped_fixes": 0,  # æ–°å¢ï¼šè·³è¿‡çš„ä¿®å¤
        }

        # å¤„ç†ç¼ºå£æ•°æ®ç»“æ„ - é€‚é…æ–°çš„æ•°æ®æ ¼å¼
        all_gaps = []
        for freq, freq_data in gap_result.get("gaps_by_frequency", {}).items():
            all_gaps.extend(freq_data.get("gaps", []))

        if not all_gaps:
            self.logger.info("æ²¡æœ‰å‘ç°ç¼ºå£ï¼Œæ— éœ€ä¿®å¤")
            return fix_result

        # é™åˆ¶ä¿®å¤æ•°é‡ï¼Œä¼˜å…ˆä¿®å¤é‡è¦è‚¡ç¥¨çš„ç¼ºå£
        max_fixes = 10
        fixes_attempted = 0

        for gap in all_gaps:
            if fixes_attempted >= max_fixes:
                break

            symbol = gap.get("symbol")
            gap_start = gap.get("start_date")
            gap_end = gap.get("end_date")
            frequency = gap.get("frequency", "1d")

            if not symbol or not gap_start or not gap_end or frequency != "1d":
                continue

            # æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦é€‚åˆä¿®å¤ï¼ˆé¿å…ä¿®å¤æ–°è‚¡æˆ–åœç‰Œè‚¡çš„ç¼ºå£ï¼‰
            stock_info = self.db_manager.fetchone(
                "SELECT list_date, status FROM stocks WHERE symbol = ?", (symbol,)
            )

            if not stock_info:
                self.logger.debug(f"è·³è¿‡ä¿®å¤: {symbol} - è‚¡ç¥¨ä¿¡æ¯ä¸å­˜åœ¨")
                continue

            # æ£€æŸ¥ç¼ºå£æ˜¯å¦åœ¨è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸä¹‹å
            if stock_info["list_date"]:
                from datetime import datetime

                list_date = datetime.strptime(
                    stock_info["list_date"], "%Y-%m-%d"
                ).date()
                gap_start_date = datetime.strptime(gap_start, "%Y-%m-%d").date()

                if gap_start_date < list_date:
                    fix_result["skipped_fixes"] += 1
                    self.logger.debug(f"è·³è¿‡ä¿®å¤: {symbol} ç¼ºå£æ—¥æœŸæ—©äºä¸Šå¸‚æ—¥æœŸ")
                    continue

            fix_result["attempted_fixes"] += 1
            fixes_attempted += 1

            self.logger.info(f"ä¿®å¤ç¼ºå£: {symbol} {gap_start} åˆ° {gap_end}")

            # è·å–æ•°æ®å¡«è¡¥ç¼ºå£
            daily_data = self.data_source_manager.get_daily_data(
                symbol, gap_start, gap_end
            )

            if isinstance(daily_data, dict) and "data" in daily_data:
                daily_data = daily_data["data"]

            # å®é™…å¤„ç†æ•°æ®æ’å…¥
            if (
                daily_data is not None
                and hasattr(daily_data, "__len__")
                and len(daily_data) > 0
            ):
                try:
                    # ä½¿ç”¨å¤„ç†å¼•æ“æ’å…¥ç¼ºå£æ•°æ®
                    processed_result = self.processing_engine.process_symbol_data(
                        symbol, str(gap_start), str(gap_end), frequency
                    )
                    records_inserted = processed_result.get("records", 0)

                    if records_inserted > 0:
                        fix_result["successful_fixes"] += 1
                        self.logger.info(
                            f"ç¼ºå£ä¿®å¤æˆåŠŸ: {symbol} æ’å…¥{records_inserted}æ¡è®°å½•"
                        )
                    else:
                        fix_result["failed_fixes"] += 1
                        self.logger.warning(
                            f"ç¼ºå£ä¿®å¤å¤±è´¥: {symbol} å¤„ç†å¼•æ“æœªæ’å…¥æ•°æ®"
                        )
                except Exception as e:
                    fix_result["failed_fixes"] += 1
                    self.logger.warning(f"ç¼ºå£ä¿®å¤å‡ºé”™: {symbol} - {e}")
            else:
                fix_result["failed_fixes"] += 1
                self.logger.debug(f"ç¼ºå£ä¿®å¤è·³è¿‡: {symbol} æ•°æ®æºæ— æ•°æ®ï¼ˆå¯èƒ½æ­£å¸¸ï¼‰")

        self.logger.info(
            f"ç¼ºå£ä¿®å¤å®Œæˆ: å°è¯•={fix_result['attempted_fixes']}, æˆåŠŸ={fix_result['successful_fixes']}, å¤±è´¥={fix_result['failed_fixes']}, è·³è¿‡={fix_result['skipped_fixes']}"
        )

        # å¦‚æœå¤§éƒ¨åˆ†ç¼ºå£éƒ½æ— æ³•ä¿®å¤ï¼Œè¯´æ˜è¿™äº›ç¼ºå£å¯èƒ½æ˜¯æ­£å¸¸çš„
        if fix_result["attempted_fixes"] > 0:
            success_rate = (
                fix_result["successful_fixes"] / fix_result["attempted_fixes"]
            )
            if success_rate < 0.3:
                self.logger.info(
                    "ğŸ’¡ å¤§éƒ¨åˆ†ç¼ºå£æ— æ³•ä¿®å¤ï¼Œè¿™å¯èƒ½æ˜¯æ­£å¸¸ç°è±¡ï¼ˆæ–°è‚¡ã€åœç‰Œç­‰ï¼‰"
                )

        return fix_result

    def generate_sync_report(self, full_result: Dict[str, Any]) -> str:
        """ç”ŸæˆåŒæ­¥æŠ¥å‘Š"""
        report_lines = []

        # æŠ¥å‘Šå¤´éƒ¨
        report_lines.append("=" * 60)
        report_lines.append("æ•°æ®åŒæ­¥æŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append(f"åŒæ­¥æ—¶é—´: {full_result.get('start_time', '')}")
        report_lines.append(f"ç›®æ ‡æ—¥æœŸ: {full_result.get('target_date', '')}")
        report_lines.append(f"æ€»è€—æ—¶: {full_result.get('duration_seconds', 0):.2f} ç§’")
        report_lines.append("")

        # é˜¶æ®µæ±‡æ€»
        summary = full_result.get("summary", {})
        report_lines.append("é˜¶æ®µæ±‡æ€»:")
        report_lines.append(f"  æ€»é˜¶æ®µæ•°: {summary.get('total_phases', 0)}")
        report_lines.append(f"  æˆåŠŸé˜¶æ®µ: {summary.get('successful_phases', 0)}")
        report_lines.append(f"  å¤±è´¥é˜¶æ®µ: {summary.get('failed_phases', 0)}")
        report_lines.append("")

        # å¢é‡åŒæ­¥è¯¦æƒ…
        phases = full_result.get("phases", {})
        if "incremental_sync" in phases:
            phase = phases["incremental_sync"]
            report_lines.append("å¢é‡åŒæ­¥:")
            report_lines.append(f"  çŠ¶æ€: {phase['status']}")

            if phase["status"] == "completed" and "result" in phase:
                result = phase["result"]
                report_lines.append(f"  æ€»è‚¡ç¥¨æ•°: {result.get('total_symbols', 0)}")
                report_lines.append(f"  æˆåŠŸæ•°é‡: {result.get('success_count', 0)}")
                report_lines.append(f"  é”™è¯¯æ•°é‡: {result.get('error_count', 0)}")
            elif "error" in phase:
                report_lines.append(f"  é”™è¯¯: {phase['error']}")

        return "\n".join(report_lines)
